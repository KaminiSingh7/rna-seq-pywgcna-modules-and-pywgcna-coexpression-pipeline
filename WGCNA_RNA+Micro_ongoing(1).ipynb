{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "f4ddd6f2-efd3-4e29-8bfe-a9c23bd7264a",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import os\n",
    "import sys\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.patches as mpatches\n",
    "import seaborn as sns\n",
    "from scipy.cluster.hierarchy import dendrogram, linkage, fcluster\n",
    "from scipy.spatial.distance import squareform\n",
    "from scipy.stats import pearsonr, ttest_ind\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.preprocessing import StandardScaler, quantile_transform\n",
    "from numba import jit, prange\n",
    "from collections import defaultdict\n",
    "import warnings\n",
    "\n",
    "# RNA-seq specific\n",
    "from pydeseq2.dds import DeseqDataSet\n",
    "from pydeseq2.ds import DeseqStats\n",
    "\n",
    "# Microarray specific  \n",
    "from patsy import dmatrix\n",
    "from inmoose.limma import lmFit, eBayes, topTable, makeContrasts, contrasts_fit\n",
    "from statsmodels.stats.multitest import multipletests\n",
    "\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# Increase recursion limit for large dendrograms\n",
    "sys.setrecursionlimit(15000)\n",
    "\n",
    "# ============================================================================\n",
    "# OPTIMIZED FUNCTIONS WITH NUMBA (unchanged)\n",
    "# ============================================================================\n",
    "\n",
    "@jit(nopython=True, parallel=True, fastmath=True)\n",
    "def fast_correlation_numba(X):\n",
    "    n_samples, n_genes = X.shape\n",
    "    X_centered = np.empty_like(X)\n",
    "    \n",
    "    for j in prange(n_genes):\n",
    "        mean_j = np.mean(X[:, j])\n",
    "        for i in range(n_samples):\n",
    "            X_centered[i, j] = X[i, j] - mean_j\n",
    "    \n",
    "    std_devs = np.empty(n_genes)\n",
    "    for j in prange(n_genes):\n",
    "        var_sum = 0.0\n",
    "        for i in range(n_samples):\n",
    "            var_sum += X_centered[i, j] ** 2\n",
    "        std_devs[j] = np.sqrt(var_sum / (n_samples - 1))\n",
    "    \n",
    "    corr_matrix = np.empty((n_genes, n_genes))\n",
    "    for i in prange(n_genes):\n",
    "        for j in range(i, n_genes):\n",
    "            if std_devs[i] == 0 or std_devs[j] == 0:\n",
    "                corr_matrix[i, j] = 0.0\n",
    "                corr_matrix[j, i] = 0.0\n",
    "            else:\n",
    "                cov = 0.0\n",
    "                for k in range(n_samples):\n",
    "                    cov += X_centered[k, i] * X_centered[k, j]\n",
    "                cov /= (n_samples - 1)\n",
    "                corr = cov / (std_devs[i] * std_devs[j])\n",
    "                corr_matrix[i, j] = corr\n",
    "                corr_matrix[j, i] = corr\n",
    "    \n",
    "    return corr_matrix\n",
    "\n",
    "\n",
    "@jit(nopython=True, parallel=True, fastmath=True)\n",
    "def compute_TOM_numba(A):\n",
    "\n",
    "    n = A.shape[0]\n",
    "    A_work = A.copy()\n",
    "    \n",
    "    for i in range(n):\n",
    "        A_work[i, i] = 0.0\n",
    "    \n",
    "    k = np.empty(n)\n",
    "    for i in prange(n):\n",
    "        k[i] = np.sum(A_work[i, :])\n",
    "    \n",
    "    L = np.dot(A_work, A_work)\n",
    "    \n",
    "    TOM = np.empty((n, n))\n",
    "    for i in prange(n):\n",
    "        for j in range(n):\n",
    "            if i == j:\n",
    "                TOM[i, j] = 1.0\n",
    "            else:\n",
    "                min_k = min(k[i], k[j])\n",
    "                denom = min_k + 1.0 - A_work[i, j]\n",
    "                if denom < 1e-10:\n",
    "                    denom = 1e-10\n",
    "                TOM[i, j] = (L[i, j] + A_work[i, j]) / denom\n",
    "    \n",
    "    return TOM\n",
    "\n",
    "\n",
    "@jit(nopython=True, parallel=True)\n",
    "def compute_coexp_metrics_fast(tom_matrix, threshold):\n",
    "   \n",
    "    n = tom_matrix.shape[0]\n",
    "    n_coexp = np.zeros(n, dtype=np.int32)\n",
    "    mean_tom = np.zeros(n)\n",
    "    max_tom = np.zeros(n)\n",
    "    total_tom = np.zeros(n)\n",
    "    \n",
    "    for i in prange(n):\n",
    "        count = 0\n",
    "        tom_sum = 0.0\n",
    "        max_val = 0.0\n",
    "        total = 0.0\n",
    "        \n",
    "        for j in range(n):\n",
    "            if i != j:\n",
    "                val = tom_matrix[i, j]\n",
    "                total += val\n",
    "                if val > threshold:\n",
    "                    count += 1\n",
    "                    tom_sum += val\n",
    "                if val > max_val:\n",
    "                    max_val = val\n",
    "        \n",
    "        n_coexp[i] = count\n",
    "        mean_tom[i] = tom_sum / count if count > 0 else 0.0\n",
    "        max_tom[i] = max_val\n",
    "        total_tom[i] = total\n",
    "    \n",
    "    return n_coexp, mean_tom, max_tom, total_tom\n",
    "\n",
    "\n",
    "class DynamicTreeCut:\n",
    "   \n",
    "    \n",
    "    def __init__(self, min_cluster_size=20, deep_split=2, \n",
    "                 detect_cut_height=0.995, pam_stage=True, \n",
    "                 pam_respects_dendro=True, max_pam_dist=None,\n",
    "                 verbose=True):\n",
    "        self.min_cluster_size = min_cluster_size\n",
    "        self.deep_split = deep_split\n",
    "        self.detect_cut_height = detect_cut_height\n",
    "        self.pam_stage = pam_stage\n",
    "        self.pam_respects_dendro = pam_respects_dendro\n",
    "        self.max_pam_dist = max_pam_dist\n",
    "        self.verbose = verbose\n",
    "    \n",
    "    def _get_cut_height(self, linkage_matrix):\n",
    "        merge_heights = linkage_matrix[:, 2]\n",
    "        percentile_5 = np.percentile(merge_heights, 5)\n",
    "        max_height = np.max(merge_heights)\n",
    "        cut_height = percentile_5 + self.detect_cut_height * (max_height - percentile_5)\n",
    "        return cut_height, percentile_5, max_height\n",
    "    \n",
    "    def _get_clusters_at_height(self, linkage_matrix, cut_height):\n",
    "        labels = fcluster(linkage_matrix, t=cut_height, criterion='distance')\n",
    "        return labels\n",
    "    \n",
    "    def _filter_small_clusters(self, labels):\n",
    "        unique_labels = np.unique(labels)\n",
    "        label_counts = {label: np.sum(labels == label) for label in unique_labels}\n",
    "        \n",
    "        new_labels = labels.copy()\n",
    "        for label, count in label_counts.items():\n",
    "            if count < self.min_cluster_size:\n",
    "                new_labels[labels == label] = 0\n",
    "        \n",
    "        valid_labels = [l for l in np.unique(new_labels) if l != 0]\n",
    "        label_map = {old: new for new, old in enumerate(valid_labels, start=1)}\n",
    "        label_map[0] = 0\n",
    "        \n",
    "        final_labels = np.array([label_map[l] for l in new_labels])\n",
    "        return final_labels\n",
    "    \n",
    "    def _pam_reassignment(self, dissim_matrix, labels, linkage_matrix):\n",
    "        n_genes = len(labels)\n",
    "        reassigned_labels = labels.copy()\n",
    "        \n",
    "        unassigned_idx = np.where(labels == 0)[0]\n",
    "        assigned_idx = np.where(labels != 0)[0]\n",
    "        \n",
    "        if len(unassigned_idx) == 0 or len(assigned_idx) == 0:\n",
    "            return reassigned_labels\n",
    "        \n",
    "        if self.max_pam_dist is None:\n",
    "            max_pam_dist = np.percentile(dissim_matrix[dissim_matrix > 0], 95)\n",
    "        else:\n",
    "            max_pam_dist = self.max_pam_dist\n",
    "        \n",
    "        for gene_idx in unassigned_idx:\n",
    "            distances_to_assigned = dissim_matrix[gene_idx, assigned_idx]\n",
    "            closest_assigned_idx = assigned_idx[np.argmin(distances_to_assigned)]\n",
    "            min_distance = distances_to_assigned[np.argmin(distances_to_assigned)]\n",
    "            \n",
    "            if min_distance < max_pam_dist:\n",
    "                closest_module = labels[closest_assigned_idx]\n",
    "                \n",
    "                if self.pam_respects_dendro:\n",
    "                    module_members = np.where(labels == closest_module)[0]\n",
    "                    mean_dist_to_module = np.mean(dissim_matrix[gene_idx, module_members])\n",
    "                    \n",
    "                    if mean_dist_to_module < max_pam_dist:\n",
    "                        reassigned_labels[gene_idx] = closest_module\n",
    "                else:\n",
    "                    reassigned_labels[gene_idx] = closest_module\n",
    "        \n",
    "        if self.verbose:\n",
    "            n_reassigned = np.sum(reassigned_labels != labels)\n",
    "            print(f\"  PAM stage: Reassigned {n_reassigned} genes\")\n",
    "        \n",
    "        return reassigned_labels\n",
    "    \n",
    "    def cut_tree(self, linkage_matrix, dissim_matrix=None):\n",
    "        cut_height, ref_height, max_height = self._get_cut_height(linkage_matrix)\n",
    "        \n",
    "        if self.verbose:\n",
    "            \n",
    "            print(f\"  Min module size: {self.min_cluster_size}\")\n",
    "            print(f\"  deepSplit: {self.deep_split}\")\n",
    "            print(f\"  Cut height: {cut_height:.4f} (detectCutHeight: {self.detect_cut_height})\")\n",
    "            print(f\"  PAM stage: {self.pam_stage}\")\n",
    "        \n",
    "        initial_labels = self._get_clusters_at_height(linkage_matrix, cut_height)\n",
    "        n_initial = len(np.unique(initial_labels))\n",
    "        \n",
    "        if self.verbose:\n",
    "            print(f\"  Initial clusters: {n_initial}\")\n",
    "        \n",
    "        filtered_labels = self._filter_small_clusters(initial_labels)\n",
    "        n_after_filter = len(np.unique(filtered_labels[filtered_labels != 0]))\n",
    "        \n",
    "        if self.verbose:\n",
    "            print(f\"  Modules after filtering: {n_after_filter}\")\n",
    "            print(f\"  Unassigned genes: {np.sum(filtered_labels == 0)}\")\n",
    "        \n",
    "        if self.pam_stage and dissim_matrix is not None:\n",
    "            final_labels = self._pam_reassignment(dissim_matrix, filtered_labels, linkage_matrix)\n",
    "        else:\n",
    "            final_labels = filtered_labels\n",
    "        \n",
    "        return final_labels\n",
    "\n",
    "\n",
    "def merge_close_modules(module_labels, module_eigengenes, merge_cut_height=0.15, \n",
    "                       dissim_matrix=None, verbose=True):\n",
    "    \n",
    "    if verbose:\n",
    "        print(f\"\\n=== Merging Close Modules (cutHeight={merge_cut_height}) ===\")\n",
    "    \n",
    "    unique_modules = [col for col in module_eigengenes.columns if col != 'ME_grey']\n",
    "    n_modules = len(unique_modules)\n",
    "    \n",
    "    if n_modules <= 1:\n",
    "        if verbose:\n",
    "            print(\"  No modules to merge\")\n",
    "        return module_labels, {}\n",
    "    \n",
    "    me_cor = module_eigengenes[unique_modules].corr()\n",
    "    me_dissim = 1 - me_cor.abs()\n",
    "    \n",
    "    condensed_me_dist = squareform(me_dissim.values, checks=False)\n",
    "    me_linkage = linkage(condensed_me_dist, method='average')\n",
    "    \n",
    "    merge_labels = fcluster(me_linkage, t=merge_cut_height, criterion='distance')\n",
    "    \n",
    "    merged_module_labels = module_labels.copy()\n",
    "    module_name_array = np.array([m if m != 'grey' else 'grey' for m in module_labels])\n",
    "    \n",
    "    merge_map_final = {}\n",
    "    for merge_group in np.unique(merge_labels):\n",
    "        modules_in_group = [m.replace('ME_', '') for i, m in enumerate(unique_modules) \n",
    "                          if merge_labels[i] == merge_group]\n",
    "        representative = modules_in_group[0]\n",
    "        for mod in modules_in_group:\n",
    "            merge_map_final[mod] = representative\n",
    "    \n",
    "    for i, mod in enumerate(module_name_array):\n",
    "        if mod in merge_map_final:\n",
    "            merged_module_labels[i] = merge_map_final[mod]\n",
    "    \n",
    "    unique_merged = np.unique([m for m in merged_module_labels if m != 'grey'])\n",
    "    \n",
    "    if verbose:\n",
    "        print(f\"  Modules before merging: {n_modules}\")\n",
    "        print(f\"  Modules after merging: {len(unique_merged)}\")\n",
    "    \n",
    "    return merged_module_labels, merge_map_final\n",
    "\n",
    "\n",
    "\n",
    "class PyWGCNA:\n",
    "\n",
    "    \n",
    "    def __init__(self, data_type='rna_seq', output_dir='output_wgcna'):\n",
    "        \n",
    "        self.data_type = data_type.lower()\n",
    "        self.output_dir = output_dir\n",
    "        os.makedirs(output_dir, exist_ok=True)\n",
    "        \n",
    "        # Analysis parameters\n",
    "        self.wgcna_input = None\n",
    "        self.normalized_data = None\n",
    "        self.deg_results = None\n",
    "        self.metadata = None\n",
    "        self.soft_power = None\n",
    "        self.module_colors = None\n",
    "        self.module_eigengenes = None\n",
    "        \n",
    "\n",
    "        \n",
    "        \n",
    "    \n",
    "    def get_platform_parameters(self):\n",
    "        \n",
    "        if self.data_type == 'microarray':\n",
    "            return {\n",
    "                # Soft power selection\n",
    "                'power_range': (1, 20),           # Broader range for microarray\n",
    "                'r2_threshold': 0.80,             # Standard threshold\n",
    "                'min_r2_accept': 0.80,                                # Minimum acceptable\n",
    "                'max_mean_k': 200,                # Avoid over-connection\n",
    "                \n",
    "                # Module detection\n",
    "                'min_module_size': 30,            # Larger to avoid noise modules\n",
    "                'deep_split': 3,                  # Higher sensitivity (0-4 scale)\n",
    "                'detect_cut_height': 0.990,       # Lower = more modules\n",
    "                'pam_stage': True,\n",
    "                'pam_respects_dendro': False,     # More flexible reassignment\n",
    "                \n",
    "                # Module merging\n",
    "                'merge_cut_height': 0.25,         # Higher = less aggressive merging\n",
    "                \n",
    "                # Data filtering\n",
    "                'variance_percentile': 50,        # Keep top 50% variable genes\n",
    "                'min_samples': 10                 # Minimum recommended samples\n",
    "            }\n",
    "        else:  # rna_seq\n",
    "            return {\n",
    "                # Soft power selection\n",
    "                'power_range': (1, 20),           # Full range\n",
    "                'r2_threshold': 0.80,             # Stricter for RNA-seq\n",
    "                'min_r2_accept': 0.80,\n",
    "                'max_mean_k': 200,\n",
    "                \n",
    "                # Module detection\n",
    "                'min_module_size': 30,            # Standard size\n",
    "                'deep_split': 2,                  # Moderate sensitivity\n",
    "                'detect_cut_height': 0.995,       # Higher = fewer, larger modules\n",
    "                'pam_stage': True,\n",
    "                'pam_respects_dendro': True,      # Respect hierarchy\n",
    "                \n",
    "                # Module merging\n",
    "                'merge_cut_height': 0.15,         # Standard merging\n",
    "                \n",
    "                # Data filtering\n",
    "                'variance_percentile': 25,        # Keep top 75% (broader for RNA-seq)\n",
    "                'min_samples': 10\n",
    "            }\n",
    "    \n",
    "    def load_data(self, count_matrix_path, metadata_path):\n",
    "        \"\"\"Load expression data and metadata\"\"\"\n",
    "        print(\"\\n=== LOADING DATA ===\")\n",
    "        count = pd.read_csv(count_matrix_path, index_col=0)\n",
    "        self.metadata = pd.read_csv(metadata_path, index_col=0)\n",
    "        \n",
    "        # Align samples\n",
    "        common_samples = list(set(count.columns) & set(self.metadata.index))\n",
    "        self.count_matrix = count[common_samples]\n",
    "        self.metadata = self.metadata.loc[common_samples]\n",
    "        \n",
    "        params = self.get_platform_parameters()\n",
    "        n_samples = len(common_samples)\n",
    "        \n",
    "        print(f\"  Initial dimensions: {self.count_matrix.shape}\")\n",
    "        print(f\"  Aligned samples: {n_samples}\")\n",
    "        \n",
    "        if n_samples < params['min_samples']:\n",
    "            print(f\"  ⚠ WARNING: Only {n_samples} samples detected!\")\n",
    "            print(f\"  Recommended minimum: {params['min_samples']} for robust WGCNA\")\n",
    "            print(f\"  Results may be less reliable with small sample sizes\")\n",
    "        \n",
    "        return self\n",
    "    \n",
    "    def preprocess_rnaseq(self, group_column, case_label, control_label, \n",
    "                         min_count=10, padj_threshold=0.05, lfc_threshold= 1):\n",
    "        \n",
    "        print(\"\\n=== PREPROCESSING RNA-SEQ DATA ===\")\n",
    "        print(\"  Method: DESeq2 with variance stabilizing transformation (VST)\")\n",
    "        \n",
    "        # Filter low-count genes\n",
    "        self.count_matrix = self.count_matrix.loc[:, (self.count_matrix.sum(axis=0) >= min_count)]\n",
    "        print(f\"  After low-count filtering: {self.count_matrix.shape}\")\n",
    "        \n",
    "        # Run DESeq2\n",
    "        print(\"  Running DESeq2...\")\n",
    "        count_t = self.count_matrix.T.astype(int)\n",
    "        metadata_aligned = self.metadata.copy()\n",
    "        metadata_aligned.index = count_t.index\n",
    "        \n",
    "        dds = DeseqDataSet(counts=count_t, metadata=metadata_aligned, \n",
    "                          design_factors=group_column, n_cpus=4)\n",
    "        dds.deseq2()\n",
    "        dds.vst()\n",
    "        \n",
    "        # Get normalized data (VST)\n",
    "        self.normalized_data = pd.DataFrame(dds.layers['vst_counts'].T, \n",
    "                                           index=self.count_matrix.index, \n",
    "                                           columns=self.count_matrix.columns)\n",
    "        \n",
    "        print(f\"  ✓ VST normalization complete\")\n",
    "        print(f\"  Normalized data range: [{self.normalized_data.min().min():.2f}, {self.normalized_data.max().max():.2f}]\")\n",
    "        \n",
    "        # Get DE results\n",
    "        stat_res = DeseqStats(dds, contrast=[group_column, case_label, control_label], \n",
    "                            alpha=padj_threshold, n_cpus=4)\n",
    "        stat_res.summary()\n",
    "        self.deg_results = stat_res.results_df\n",
    "        \n",
    "        sig_degs = self.deg_results[\n",
    "            (self.deg_results['padj'] < padj_threshold) & \n",
    "            (abs(self.deg_results['log2FoldChange']) > lfc_threshold)\n",
    "        ]\n",
    "        print(f\"  DEGs found: {len(sig_degs)} (padj<{padj_threshold}, |log2FC|>{lfc_threshold})\")\n",
    "        \n",
    "        return self\n",
    "    \n",
    "    def preprocess_microarray(self, group_column, case_label, control_label,\n",
    "                             covariates=None, normalize=True, \n",
    "                             padj_threshold=0.05, lfc_threshold=1):\n",
    "        \n",
    "        print(\"  Method: limma with empirical Bayes moderation\")\n",
    "        \n",
    "        expr_data = self.count_matrix.copy()\n",
    "        expr_data = expr_data.fillna(0)\n",
    "        \n",
    "        # Log2 transform if needed\n",
    "        max_val = expr_data.max().max()\n",
    "        if max_val > 100:\n",
    "            print(f\"  Data appears non-log scale (max={max_val:.1f})\")\n",
    "            print(\"  Applying log2(x+1) transformation...\")\n",
    "            expr_data = expr_data.mask(expr_data <= 0, 1e-6)\n",
    "            expr_data = np.log2(expr_data + 1)\n",
    "        else:\n",
    "            print(f\"  Data appears log-scale (max={max_val:.2f})\")\n",
    "        \n",
    "        # Quantile normalization\n",
    "        if normalize:\n",
    "            print(\"  Applying quantile normalization...\")\n",
    "            expr_array = quantile_transform(expr_data.values, axis=0, \n",
    "                                          copy=True, output_distribution='normal')\n",
    "            expr_data = pd.DataFrame(expr_array, index=expr_data.index, \n",
    "                                    columns=expr_data.columns)\n",
    "            print(f\"  ✓ Normalization complete\")\n",
    "        \n",
    "        self.normalized_data = expr_data\n",
    "        print(f\"  Normalized data range: [{expr_data.min().min():.2f}, {expr_data.max().max():.2f}]\")\n",
    "        \n",
    "        # Create design matrix\n",
    "        print(\"  Creating design matrix...\")\n",
    "        self.metadata['Label'] = self.metadata[group_column].apply(\n",
    "            lambda x: 'Disease' if x == case_label else 'Control'\n",
    "        )\n",
    "        \n",
    "        if covariates:\n",
    "            formula = f\"~ 0 + Label + {' + '.join(covariates)}\"\n",
    "            print(f\"  Including covariates: {', '.join(covariates)}\")\n",
    "        else:\n",
    "            formula = \"~ 0 + Label\"\n",
    "        \n",
    "        design_mat = dmatrix(formula, data=self.metadata)\n",
    "        \n",
    "        # Fit limma\n",
    "        print(\"  Fitting linear model...\")\n",
    "        fit = lmFit(expr_data, design_mat)\n",
    "        \n",
    "        print(\"  Applying empirical Bayes moderation...\")\n",
    "        contrast_matrix = makeContrasts(\"Label[Disease] - Label[Control]\", design_mat)\n",
    "        fit2 = contrasts_fit(fit, contrast_matrix)\n",
    "        fit2 = eBayes(fit2)\n",
    "        \n",
    "        print(\"  Extracting differential expression results...\")\n",
    "        results = topTable(fit2, coef='Label[Disease] - Label[Control]', \n",
    "                          adjust_method=\"fdr_bh\", number=np.inf)\n",
    "        self.deg_results = pd.DataFrame(results)\n",
    "        \n",
    "        sig_degs = self.deg_results[\n",
    "            (self.deg_results['adj_pvalue'] < padj_threshold) & \n",
    "            (abs(self.deg_results['log2FoldChange']) > lfc_threshold)\n",
    "        ]\n",
    "        print(f\"  DEGs found: {len(sig_degs)} (FDR<{padj_threshold}, |log2FC|>{lfc_threshold})\")\n",
    "        \n",
    "        return self\n",
    "    \n",
    "    def prepare_wgcna_input(self, custom_variance_percentile=None):\n",
    "        \n",
    "        params = self.get_platform_parameters()\n",
    "        variance_percentile = custom_variance_percentile or params['variance_percentile']\n",
    "        \n",
    "        gene_var = self.normalized_data.var(axis=1)\n",
    "        top_var_threshold = gene_var.quantile(variance_percentile / 100)\n",
    "        filtered_data = self.normalized_data[gene_var > top_var_threshold]\n",
    "        \n",
    "        self.wgcna_input = filtered_data.T  # Samples x Genes\n",
    "        \n",
    "        print(f\"  Variance filtering: Keep top {100-variance_percentile}% variable genes\")\n",
    "        print(f\"  Variance threshold: {top_var_threshold:.3f}\")\n",
    "        print(f\"  WGCNA input: {self.wgcna_input.shape[0]} samples × {self.wgcna_input.shape[1]} genes\")\n",
    "        \n",
    "        if self.wgcna_input.shape[1] < 1000:\n",
    "            print(f\"  ⚠ WARNING: Only {self.wgcna_input.shape[1]} genes in network\")\n",
    "            print(f\"  Consider reducing variance_percentile for more genes\")\n",
    "        \n",
    "        return self\n",
    "    \n",
    "    def select_soft_power(self, custom_power_range=None, custom_r2_threshold=None):\n",
    "      \n",
    "        params = self.get_platform_parameters()\n",
    "        power_range = custom_power_range or params['power_range']\n",
    "        r2_threshold = custom_r2_threshold or params['r2_threshold']\n",
    "        \n",
    "        print(f\"  Platform: {self.data_type.upper()}\")\n",
    "        print(f\"  Target R² threshold: {r2_threshold}\")\n",
    "        print(f\"  Power range: {power_range}\")\n",
    "        \n",
    "        # Compute correlation matrix\n",
    "        print(\"  Computing correlation matrix...\")\n",
    "        X = self.wgcna_input.values\n",
    "        cor_matrix_np = fast_correlation_numba(X)\n",
    "        \n",
    "        # Use subset for large datasets (computational efficiency)\n",
    "        n_genes = cor_matrix_np.shape[0]\n",
    "        max_genes_for_selection = 5000\n",
    "        \n",
    "        if n_genes > max_genes_for_selection:\n",
    "            print(f\"  Using {max_genes_for_selection} random genes for power selection (dataset has {n_genes})\")\n",
    "            np.random.seed(42)\n",
    "            subset_idx = np.random.choice(n_genes, min(max_genes_for_selection, n_genes), replace=False)\n",
    "            cor_subset = cor_matrix_np[np.ix_(subset_idx, subset_idx)]\n",
    "        else:\n",
    "            cor_subset = cor_matrix_np\n",
    "        \n",
    "        cor_abs = np.abs(cor_subset)\n",
    "        powers = range(*power_range)\n",
    "        mean_k = []\n",
    "        median_k = []\n",
    "        r_squared = []\n",
    "        slope_values = []\n",
    "        \n",
    "        print(\"  Testing soft powers...\")\n",
    "        for power in powers:\n",
    "            adj_temp = cor_abs ** power\n",
    "            k_temp = adj_temp.sum(axis=1)\n",
    "            mean_k.append(k_temp.mean())\n",
    "            median_k.append(np.median(k_temp))\n",
    "            \n",
    "            # Calculate scale-free topology fit (R²)\n",
    "            k_hist, k_bins = np.histogram(k_temp[k_temp > 1], bins=30)\n",
    "            k_centers = (k_bins[:-1] + k_bins[1:]) / 2\n",
    "            k_centers = k_centers[k_hist > 0]\n",
    "            k_hist = k_hist[k_hist > 0]\n",
    "            \n",
    "            if len(k_centers) > 5:\n",
    "                log_k = np.log10(k_centers)\n",
    "                log_p = np.log10(k_hist / k_hist.sum())\n",
    "                mask = np.isfinite(log_k) & np.isfinite(log_p)\n",
    "                \n",
    "                if mask.sum() > 5:\n",
    "                    slope, intercept = np.polyfit(log_k[mask], log_p[mask], 1)\n",
    "                    r2 = np.corrcoef(log_k[mask], log_p[mask])[0, 1] ** 2\n",
    "                    slope_values.append(slope)\n",
    "                else:\n",
    "                    r2 = 0\n",
    "                    slope_values.append(0)\n",
    "            else:\n",
    "                r2 = 0\n",
    "                slope_values.append(0)\n",
    "            \n",
    "            r_squared.append(r2)\n",
    "        \n",
    "        # Plot soft power selection\n",
    "        fig, axes = plt.subplots(2, 2, figsize=(16, 12))\n",
    "        \n",
    "        # R² plot\n",
    "        ax1 = axes[0, 0]\n",
    "        ax1.plot(powers, r_squared, 'o-', linewidth=2.5, markersize=8, color='#2E86AB')\n",
    "        ax1.axhline(y=r2_threshold, color='red', linestyle='--', linewidth=2, \n",
    "                   label=f'Target R² = {r2_threshold}')\n",
    "        ax1.axhline(y=params['min_r2_accept'], color='orange', linestyle=':', linewidth=1.5,\n",
    "                   label=f'Min acceptable R² = {params[\"min_r2_accept\"]}')\n",
    "        ax1.set_xlabel('Soft Threshold Power (β)', fontsize=12, fontweight='bold')\n",
    "        ax1.set_ylabel('Scale Free Topology Fit (R²)', fontsize=12, fontweight='bold')\n",
    "        ax1.set_title(f'Scale Independence ({self.data_type.upper()})', fontsize=14, fontweight='bold')\n",
    "        ax1.legend(fontsize=10)\n",
    "        ax1.grid(alpha=0.3)\n",
    "        ax1.set_xlim([powers[0]-0.5, powers[-1]+0.5])\n",
    "        \n",
    "        # Mean connectivity plot\n",
    "        ax2 = axes[0, 1]\n",
    "        ax2.plot(powers, mean_k, 'o-', linewidth=2.5, markersize=8, color='#06A77D')\n",
    "        if params['max_mean_k']:\n",
    "            ax2.axhline(y=params['max_mean_k'], color='red', linestyle='--', linewidth=2,\n",
    "                       label=f'Max mean k = {params[\"max_mean_k\"]}')\n",
    "            ax2.legend(fontsize=10)\n",
    "        ax2.set_xlabel('Soft Threshold Power (β)', fontsize=12, fontweight='bold')\n",
    "        ax2.set_ylabel('Mean Connectivity', fontsize=12, fontweight='bold')\n",
    "        ax2.set_title('Mean Connectivity', fontsize=14, fontweight='bold')\n",
    "        ax2.grid(alpha=0.3)\n",
    "        ax2.set_xlim([powers[0]-0.5, powers[-1]+0.5])\n",
    "        \n",
    "        # Median connectivity plot\n",
    "        ax3 = axes[1, 0]\n",
    "        ax3.plot(powers, median_k, 'o-', linewidth=2.5, markersize=8, color='#F18F01')\n",
    "        ax3.set_xlabel('Soft Threshold Power (β)', fontsize=12, fontweight='bold')\n",
    "        ax3.set_ylabel('Median Connectivity', fontsize=12, fontweight='bold')\n",
    "        ax3.set_title('Median Connectivity', fontsize=14, fontweight='bold')\n",
    "        ax3.grid(alpha=0.3)\n",
    "        ax3.set_xlim([powers[0]-0.5, powers[-1]+0.5])\n",
    "        \n",
    "        # Network density (slope) plot\n",
    "        ax4 = axes[1, 1]\n",
    "        ax4.plot(powers, [-s for s in slope_values], 'o-', linewidth=2.5, markersize=8, color='#A23B72')\n",
    "        ax4.set_xlabel('Soft Threshold Power (β)', fontsize=12, fontweight='bold')\n",
    "        ax4.set_ylabel('Scale Free Topology Slope (-slope)', fontsize=12, fontweight='bold')\n",
    "        ax4.set_title('Network Density', fontsize=14, fontweight='bold')\n",
    "        ax4.grid(alpha=0.3)\n",
    "        ax4.set_xlim([powers[0]-0.5, powers[-1]+0.5])\n",
    "        \n",
    "        plt.tight_layout()\n",
    "        plt.savefig(f'{self.output_dir}/01_Soft_Power_Selection.pdf', dpi=300, bbox_inches='tight')\n",
    "        plt.close()\n",
    "        \n",
    "        # Select optimal power using multi-criteria decision\n",
    "        print(\"\\n  Selecting optimal power...\")\n",
    "        \n",
    "        # Criterion 1: R² >= threshold\n",
    "        suitable_powers = []\n",
    "        for i, (p, r2, mk) in enumerate(zip(powers, r_squared, mean_k)):\n",
    "            if r2 >= r2_threshold and mk <= params['max_mean_k']:\n",
    "                suitable_powers.append((p, r2, mk, abs(r2 - r2_threshold)))\n",
    "        \n",
    "        # If no power meets strict threshold, relax to minimum acceptable\n",
    "        if not suitable_powers:\n",
    "            print(f\"  No power achieved R² >= {r2_threshold}\")\n",
    "            print(f\"  Relaxing to minimum acceptable R² >= {params['min_r2_accept']}\")\n",
    "            for i, (p, r2, mk) in enumerate(zip(powers, r_squared, mean_k)):\n",
    "                if r2 >= params['min_r2_accept'] and mk <= params['max_mean_k']:\n",
    "                    suitable_powers.append((p, r2, mk, abs(r2 - r2_threshold)))\n",
    "        \n",
    "        # If still none, pick highest R²\n",
    "        if not suitable_powers:\n",
    "            print(f\"  Using power with highest R² (no threshold met)\")\n",
    "            best_idx = np.argmax(r_squared)\n",
    "            self.soft_power = list(powers)[best_idx]\n",
    "            selected_r2 = r_squared[best_idx]\n",
    "            selected_mk = mean_k[best_idx]\n",
    "        else:\n",
    "            # Sort by: closest to target R², then lowest mean k\n",
    "            suitable_powers_sorted = sorted(suitable_powers, key=lambda x: (x[3], x[2]))\n",
    "            self.soft_power = suitable_powers_sorted[0][0]\n",
    "            selected_r2 = suitable_powers_sorted[0][1]\n",
    "            selected_mk = suitable_powers_sorted[0][2]\n",
    "        \n",
    "        print(f\"\\n  ✓ Selected soft power: β = {self.soft_power}\")\n",
    "        print(f\"    Scale-free R²: {selected_r2:.3f}\")\n",
    "        print(f\"    Mean connectivity: {selected_mk:.2f}\")\n",
    "        print(f\"    Interpretation: {'Excellent' if selected_r2 >= 0.85 else 'Good' if selected_r2 >= 0.80 else 'Acceptable'} scale-free fit\")\n",
    "        \n",
    "        self.cor_matrix_np = cor_matrix_np\n",
    "        self.soft_power_metrics = {\n",
    "            'power': self.soft_power,\n",
    "            'r_squared': selected_r2,\n",
    "            'mean_connectivity': selected_mk,\n",
    "            'all_r2': dict(zip(powers, r_squared)),\n",
    "            'all_mean_k': dict(zip(powers, mean_k))\n",
    "        }\n",
    "        \n",
    "        return self\n",
    "    \n",
    "    def construct_network(self, custom_params=None):\n",
    "        \n",
    "        \n",
    "        params = self.get_platform_parameters()\n",
    "        if custom_params:\n",
    "            params.update(custom_params)\n",
    "        \n",
    "        print(f\"  Platform-optimized parameters ({self.data_type.upper()}):\")\n",
    "        print(f\"    min_module_size = {params['min_module_size']}\")\n",
    "        print(f\"    deep_split = {params['deep_split']} (0=strict, 4=very sensitive)\")\n",
    "        print(f\"    detect_cut_height = {params['detect_cut_height']}\")\n",
    "        print(f\"    merge_cut_height = {params['merge_cut_height']}\")\n",
    "        \n",
    "        # Compute adjacency\n",
    "        print(f\"\\n  Applying soft power: β = {self.soft_power}\")\n",
    "        adjacency_np = np.abs(self.cor_matrix_np) ** self.soft_power\n",
    "        \n",
    "        # Compute TOM\n",
    "        print(\"  Computing Topological Overlap Matrix (TOM)...\")\n",
    "        TOM_np = compute_TOM_numba(adjacency_np)\n",
    "        self.TOM_df = pd.DataFrame(TOM_np, \n",
    "                                   index=self.wgcna_input.columns, \n",
    "                                   columns=self.wgcna_input.columns)\n",
    "        print(\"  ✓ TOM calculation complete\")\n",
    "        \n",
    "        # Hierarchical clustering\n",
    "        print(\"  Performing hierarchical clustering...\")\n",
    "        dissim_TOM = 1 - TOM_np\n",
    "        np.fill_diagonal(dissim_TOM, 0)\n",
    "        condensed_dist = squareform(dissim_TOM, checks=False)\n",
    "        self.gene_linkage = linkage(condensed_dist, method='average')\n",
    "        \n",
    "        # Dynamic tree cut\n",
    "        print(\"\\n=== DETECTING MODULES (Dynamic Tree Cut) ===\")\n",
    "        dtc = DynamicTreeCut(\n",
    "            min_cluster_size=params['min_module_size'],\n",
    "            deep_split=params['deep_split'],\n",
    "            detect_cut_height=params['detect_cut_height'],\n",
    "            pam_stage=params['pam_stage'],\n",
    "            pam_respects_dendro=params['pam_respects_dendro'],\n",
    "            verbose=True\n",
    "        )\n",
    "        \n",
    "        module_labels_numeric = dtc.cut_tree(self.gene_linkage, dissim_matrix=dissim_TOM)\n",
    "        \n",
    "        # Convert to color names\n",
    "        unique_modules = np.unique(module_labels_numeric[module_labels_numeric != 0])\n",
    "        n_modules = len(unique_modules)\n",
    "        \n",
    "        if n_modules > 0:\n",
    "            color_names = [f'module_{i}' for i in range(1, n_modules + 1)]\n",
    "            module_colors = pd.Series(index=self.wgcna_input.columns, dtype='object')\n",
    "            module_colors[:] = 'grey'\n",
    "            \n",
    "            for i, mod_num in enumerate(unique_modules):\n",
    "                genes_in_mod = self.wgcna_input.columns[module_labels_numeric == mod_num]\n",
    "                module_colors[genes_in_mod] = color_names[i]\n",
    "        else:\n",
    "            module_colors = pd.Series(['grey'] * len(self.wgcna_input.columns), \n",
    "                                     index=self.wgcna_input.columns)\n",
    "        \n",
    "        self.module_colors = module_colors\n",
    "        \n",
    "        # Calculate module eigengenes\n",
    "        print(\"\\n=== CALCULATING MODULE EIGENGENES ===\")\n",
    "        print(\"  Method: First principal component (PCA) of module expression\")\n",
    "        ME_dict = {}\n",
    "        \n",
    "        for mod in module_colors.unique():\n",
    "            if mod != 'grey':\n",
    "                genes_in_mod = module_colors[module_colors == mod].index\n",
    "                if len(genes_in_mod) > 0:\n",
    "                    pca_mod = PCA(n_components=1)\n",
    "                    me = pca_mod.fit_transform(self.wgcna_input[genes_in_mod])\n",
    "                    ME_dict[f'ME_{mod}'] = me.flatten()\n",
    "                    \n",
    "                    var_explained = pca_mod.explained_variance_ratio_[0]\n",
    "                    print(f\"    {mod}: {len(genes_in_mod)} genes, variance explained = {var_explained:.2%}\")\n",
    "        \n",
    "        if 'grey' in module_colors.values:\n",
    "            genes_in_grey = module_colors[module_colors == 'grey'].index\n",
    "            if len(genes_in_grey) > 0:\n",
    "                pca_grey = PCA(n_components=1)\n",
    "                me_grey = pca_grey.fit_transform(self.wgcna_input[genes_in_grey])\n",
    "                ME_dict['ME_grey'] = me_grey.flatten()\n",
    "        \n",
    "        self.module_eigengenes = pd.DataFrame(ME_dict, index=self.wgcna_input.index)\n",
    "        print(f\"\\n  Calculated eigengenes for {len(ME_dict)} modules\")\n",
    "        \n",
    "        # Merge close modules\n",
    "        if n_modules > 1:\n",
    "            merged_colors, merge_info = merge_close_modules(\n",
    "                self.module_colors.values,\n",
    "                self.module_eigengenes,\n",
    "                merge_cut_height=params['merge_cut_height'],\n",
    "                dissim_matrix=dissim_TOM,\n",
    "                verbose=True\n",
    "            )\n",
    "            \n",
    "            self.module_colors = pd.Series(merged_colors, index=self.module_colors.index)\n",
    "            \n",
    "            # Recalculate eigengenes after merging\n",
    "            ME_dict_merged = {}\n",
    "            for mod in self.module_colors.unique():\n",
    "                if mod != 'grey':\n",
    "                    genes_in_mod = self.module_colors[self.module_colors == mod].index\n",
    "                    if len(genes_in_mod) > 0:\n",
    "                        pca_mod = PCA(n_components=1)\n",
    "                        me = pca_mod.fit_transform(self.wgcna_input[genes_in_mod])\n",
    "                        ME_dict_merged[f'ME_{mod}'] = me.flatten()\n",
    "            \n",
    "            if 'grey' in self.module_colors.values:\n",
    "                genes_in_grey = self.module_colors[self.module_colors == 'grey'].index\n",
    "                if len(genes_in_grey) > 0:\n",
    "                    pca_grey = PCA(n_components=1)\n",
    "                    me_grey = pca_grey.fit_transform(self.wgcna_input[genes_in_grey])\n",
    "                    ME_dict_merged['ME_grey'] = me_grey.flatten()\n",
    "            \n",
    "            self.module_eigengenes = pd.DataFrame(ME_dict_merged, index=self.wgcna_input.index)\n",
    "        \n",
    "        # Final summary\n",
    "        module_counts = self.module_colors.value_counts()\n",
    "        n_modules_final = len([m for m in self.module_colors.unique() if m != 'grey'])\n",
    "        \n",
    "        print(f\"\\n=== FINAL MODULE SUMMARY ===\")\n",
    "        print(f\"  Total modules: {n_modules_final}\")\n",
    "        print(f\"  Genes in modules: {np.sum(self.module_colors != 'grey')}\")\n",
    "        print(f\"  Unassigned (grey): {np.sum(self.module_colors == 'grey')}\")\n",
    "        print(f\"\\n  Module size distribution:\")\n",
    "        for mod, count in module_counts.head(10).items():\n",
    "            print(f\"    {mod}: {count} genes\")\n",
    "        if len(module_counts) > 10:\n",
    "            print(f\"    ... and {len(module_counts)-10} more modules\")\n",
    "        \n",
    "        # Quality metrics\n",
    "        avg_module_size = np.mean([count for mod, count in module_counts.items() if mod != 'grey'])\n",
    "        print(f\"\\n  Quality metrics:\")\n",
    "        print(f\"    Average module size: {avg_module_size:.1f} genes\")\n",
    "        print(f\"    Assignment rate: {100*np.sum(self.module_colors != 'grey')/len(self.module_colors):.1f}%\")\n",
    "        \n",
    "        # Save results\n",
    "        gene_module_df = pd.DataFrame({\n",
    "            'Gene': self.module_colors.index,\n",
    "            'Module': self.module_colors.values\n",
    "        })\n",
    "        gene_module_df.to_csv(f'{self.output_dir}/Gene_Module_Assignment.csv', index=False)\n",
    "        \n",
    "        self.module_eigengenes.to_csv(f'{self.output_dir}/Module_Eigengenes.csv')\n",
    "        \n",
    "        return self\n",
    "    \n",
    "    def analyze_deg_modules(self, padj_threshold=0.05, lfc_threshold= 1, coexp_threshold=0.1):\n",
    "        \"\"\"Analyze DEGs in WGCNA modules with biological interpretation\"\"\"\n",
    "        print(\"\\n=== ANALYZING DEGS IN MODULES ===\")\n",
    "        \n",
    "        # Get significant DEGs\n",
    "        padj_col = 'padj' if 'padj' in self.deg_results.columns else 'adj_pvalue'\n",
    "        sig_genes = self.deg_results[\n",
    "            (self.deg_results[padj_col] < padj_threshold) & \n",
    "            (abs(self.deg_results['log2FoldChange']) > lfc_threshold)\n",
    "        ].dropna()\n",
    "        \n",
    "        deg_in_wgcna = list(set(sig_genes.index) & set(self.module_colors.index))\n",
    "        print(f\"  Total DEGs: {len(sig_genes)}\")\n",
    "        print(f\"  DEGs in WGCNA network: {len(deg_in_wgcna)} ({100*len(deg_in_wgcna)/len(sig_genes):.1f}%)\")\n",
    "        \n",
    "        if len(deg_in_wgcna) == 0:\n",
    "            print(\"  No DEGs found in WGCNA network!\")\n",
    "            return self\n",
    "        \n",
    "        # DEG distribution across modules\n",
    "        deg_modules = [self.module_colors[g] for g in deg_in_wgcna]\n",
    "        deg_module_counts = pd.Series(deg_modules).value_counts()\n",
    "        \n",
    "        print(f\"\\n  DEG distribution across modules:\")\n",
    "        for mod, count in deg_module_counts.head(10).items():\n",
    "            total_in_mod = np.sum(self.module_colors == mod)\n",
    "            enrichment = (count / len(deg_in_wgcna)) / (total_in_mod / len(self.module_colors))\n",
    "            print(f\"    {mod}: {count} DEGs / {total_in_mod} genes (enrichment: {enrichment:.2f}x)\")\n",
    "        \n",
    "        # Create DEG-module table\n",
    "        deg_module_df = pd.DataFrame({\n",
    "            'Gene': deg_in_wgcna,\n",
    "            'Module': [self.module_colors[g] for g in deg_in_wgcna],\n",
    "            'Log2FC': [sig_genes.loc[g, 'log2FoldChange'] for g in deg_in_wgcna],\n",
    "            'Adj_PValue': [sig_genes.loc[g, padj_col] for g in deg_in_wgcna],\n",
    "            'Regulation': ['Up' if sig_genes.loc[g, 'log2FoldChange'] > 0 else 'Down' \n",
    "                          for g in deg_in_wgcna]\n",
    "        })\n",
    "        deg_module_df.to_csv(f'{self.output_dir}/DEG_Module_Assignment.csv', index=False)\n",
    "        \n",
    "        # Co-expression analysis\n",
    "        print(f\"\\n  Computing co-expression metrics (TOM threshold = {coexp_threshold})...\")\n",
    "        deg_tom = self.TOM_df.loc[deg_in_wgcna, deg_in_wgcna]\n",
    "        \n",
    "        gene_coexp_metrics = deg_module_df.copy()\n",
    "        \n",
    "        # Compute metrics\n",
    "        n_coexp, mean_tom, max_tom, total_tom = compute_coexp_metrics_fast(\n",
    "            deg_tom.values, coexp_threshold\n",
    "        )\n",
    "        \n",
    "        gene_coexp_metrics['N_CoExpressed_Genes'] = n_coexp\n",
    "        gene_coexp_metrics['Mean_TOM_Score'] = mean_tom\n",
    "        gene_coexp_metrics['Max_TOM_Score'] = max_tom\n",
    "        \n",
    "        # Module membership (kME)\n",
    "        print(\"  Calculating module membership (kME)...\")\n",
    "        mm_values = []\n",
    "        for g in gene_coexp_metrics['Gene']:\n",
    "            gene_module = gene_coexp_metrics[gene_coexp_metrics['Gene']==g]['Module'].values[0]\n",
    "            me_col = f\"ME_{gene_module}\"\n",
    "            \n",
    "            if me_col in self.module_eigengenes.columns:\n",
    "                corr, _ = pearsonr(self.wgcna_input[g], self.module_eigengenes[me_col])\n",
    "                mm_values.append(corr)\n",
    "            else:\n",
    "                mm_values.append(np.nan)\n",
    "        \n",
    "        gene_coexp_metrics['Module_Membership'] = mm_values\n",
    "        \n",
    "        gene_coexp_metrics = gene_coexp_metrics.sort_values(\n",
    "            ['N_CoExpressed_Genes', 'Mean_TOM_Score'], \n",
    "            ascending=[False, False]\n",
    "        ).reset_index(drop=True)\n",
    "        \n",
    "        gene_coexp_metrics.to_csv(f'{self.output_dir}/Gene_Coexpression_Metrics.csv', index=False)\n",
    "        \n",
    "        print(\"\\n Top 10 hub DEGs (highest co-expression):\")\n",
    "        print(gene_coexp_metrics[['Gene', 'Module', 'N_CoExpressed_Genes', \n",
    "                                   'Module_Membership', 'Log2FC']].head(10).to_string(index=False))\n",
    "        \n",
    "        return self\n",
    "    \n",
    "    def create_visualizations(self):\n",
    "        \n",
    "        \n",
    "        # Module dendrogram (with error handling for large datasets)\n",
    "        try:\n",
    "            self._plot_dendrogram()\n",
    "        except RecursionError:\n",
    "            print(\"  ⚠ Dendrogram plotting failed (too many genes)\")\n",
    "            print(\"  Creating module size plot instead...\")\n",
    "            self._plot_module_sizes()\n",
    "        \n",
    "    \n",
    "        \n",
    "        # Module eigengene heatmap\n",
    "        self._plot_eigengene_heatmap()\n",
    "        \n",
    "        print(\"  ✓ All visualizations complete!\")\n",
    "        \n",
    "        return self\n",
    "    \n",
    "    def _plot_dendrogram(self, max_genes=5000):\n",
    "        \n",
    "        n_genes = len(self.wgcna_input.columns)\n",
    "        \n",
    "        fig = plt.figure(figsize=(22, 12))\n",
    "        gs = fig.add_gridspec(2, 1, height_ratios=[4, 1], hspace=0.05)\n",
    "        ax1 = fig.add_subplot(gs[0])\n",
    "        ax2 = fig.add_subplot(gs[1])\n",
    "        \n",
    "        if n_genes > max_genes:\n",
    "            print(f\"  Creating truncated dendrogram ({n_genes} genes)...\")\n",
    "            dend = dendrogram(\n",
    "                self.gene_linkage, \n",
    "                ax=ax1, \n",
    "                no_labels=True,\n",
    "                truncate_mode='lastp',\n",
    "                p=100,\n",
    "                above_threshold_color='gray'\n",
    "            )\n",
    "            ax1.set_title(f'Gene Dendrogram (Truncated) - {n_genes} genes total', \n",
    "                         fontsize=16, fontweight='bold')\n",
    "        else:\n",
    "            dend = dendrogram(\n",
    "                self.gene_linkage, \n",
    "                labels=self.wgcna_input.columns, \n",
    "                ax=ax1, \n",
    "                no_labels=True, \n",
    "                above_threshold_color='gray'\n",
    "            )\n",
    "            ax1.set_title(f'Gene Dendrogram and Module Colors - {n_genes} genes', \n",
    "                         fontsize=16, fontweight='bold')\n",
    "        \n",
    "        ax1.set_ylabel('Height (1-TOM)', fontsize=13, fontweight='bold')\n",
    "        ax1.spines['bottom'].set_visible(False)\n",
    "        ax1.set_xticks([])\n",
    "        \n",
    "        # Color bar\n",
    "        module_counts = self.module_colors.value_counts()\n",
    "        color_map = {}\n",
    "        colors = plt.cm.tab20c(np.linspace(0, 1, 20))\n",
    "        \n",
    "        for i, mod in enumerate(self.module_colors.unique()):\n",
    "            if mod == 'grey':\n",
    "                color_map[mod] = (0.7, 0.7, 0.7)\n",
    "            else:\n",
    "                color_map[mod] = tuple(colors[i % 20][:3])\n",
    "        \n",
    "        if n_genes <= max_genes:\n",
    "            leaf_order = dend['leaves']\n",
    "            ordered_colors = np.array([color_map[self.module_colors.iloc[i]] for i in leaf_order])\n",
    "            color_array = ordered_colors.reshape(1, -1, 3)\n",
    "            \n",
    "            ax2.imshow(color_array, aspect='auto', interpolation='nearest')\n",
    "            ax2.set_yticks([])\n",
    "            ax2.set_xticks([])\n",
    "            ax2.set_ylabel('Module', fontsize=11, fontweight='bold')\n",
    "        else:\n",
    "            ax2.axis('off')\n",
    "            stats_text = \"Module Distribution:\\n\" + \"\\n\".join(\n",
    "                [f\"{mod}: {count}\" for mod, count in module_counts.head(8).items()]\n",
    "            )\n",
    "            ax2.text(0.1, 0.5, stats_text, transform=ax2.transAxes, \n",
    "                    fontsize=10, family='monospace')\n",
    "        \n",
    "        # Legend\n",
    "        legend_elements = []\n",
    "        for mod in list(self.module_colors.unique())[:12]:\n",
    "            if mod in color_map:\n",
    "                legend_elements.append(mpatches.Patch(\n",
    "                    color=color_map[mod], \n",
    "                    label=f'{mod} (n={module_counts[mod]})'\n",
    "                ))\n",
    "        \n",
    "        ax1.legend(handles=legend_elements, loc='upper right', fontsize=9, ncol=2)\n",
    "        \n",
    "        plt.tight_layout()\n",
    "        plt.savefig(f'{self.output_dir}/02_Module_Dendrogram.pdf', dpi=300, bbox_inches='tight')\n",
    "        plt.close()\n",
    "        print(\"  Dendrogram saved\")\n",
    "    \n",
    "    def _plot_module_sizes(self):\n",
    "        \n",
    "        module_counts = self.module_colors.value_counts()\n",
    "        module_counts = module_counts[module_counts.index != 'grey'].sort_values(ascending=False)\n",
    "        \n",
    "        fig, ax = plt.subplots(figsize=(14, 8))\n",
    "        \n",
    "        bars = ax.bar(range(len(module_counts)), module_counts.values,\n",
    "                     color=plt.cm.tab20(np.linspace(0, 1, len(module_counts))),\n",
    "                     edgecolor='black', linewidth=1.2)\n",
    "        \n",
    "        ax.set_xticks(range(len(module_counts)))\n",
    "        ax.set_xticklabels(module_counts.index, rotation=45, ha='right', fontsize=9)\n",
    "        ax.set_xlabel('Module', fontsize=13, fontweight='bold')\n",
    "        ax.set_ylabel('Number of Genes', fontsize=13, fontweight='bold')\n",
    "        ax.set_title(f'Module Size Distribution - {len(module_counts)} modules', \n",
    "                    fontsize=15, fontweight='bold')\n",
    "        ax.grid(axis='y', alpha=0.3)\n",
    "        \n",
    "        plt.tight_layout()\n",
    "        plt.savefig(f'{self.output_dir}/02_Module_Sizes.pdf', dpi=300, bbox_inches='tight')\n",
    "        plt.close()\n",
    "        print(\"  ✓ Module size plot saved\")\n",
    "    \n",
    "    \n",
    "    \n",
    "    def _plot_eigengene_heatmap(self):\n",
    "       \n",
    "        if len(self.module_eigengenes.columns) < 2:\n",
    "            print(\"  Skipping eigengene heatmap (need ≥2 modules)\")\n",
    "            return\n",
    "        \n",
    "        # Filter out grey if present\n",
    "        me_cols = [col for col in self.module_eigengenes.columns if 'grey' not in col.lower()]\n",
    "        if len(me_cols) < 2:\n",
    "            return\n",
    "        \n",
    "        me_data = self.module_eigengenes[me_cols]\n",
    "        \n",
    "        plt.figure(figsize=(14, max(6, len(me_cols)*0.3)))\n",
    "        \n",
    "        sns.clustermap(me_data.T, cmap='RdBu_r', center=0, \n",
    "                      figsize=(14, max(8, len(me_cols)*0.5)),\n",
    "                      yticklabels=True, xticklabels=False,\n",
    "                      cbar_kws={'label': 'Eigengene Expression'})\n",
    "        \n",
    "        plt.suptitle('Module Eigengene Expression Heatmap', \n",
    "                    fontsize=15, fontweight='bold', y=1.02)\n",
    "        plt.tight_layout()\n",
    "        plt.savefig(f'{self.output_dir}/04_Eigengene_Heatmap.pdf', dpi=300, bbox_inches='tight')\n",
    "        plt.close()\n",
    "        \n",
    "        print(\"  ✓ Eigengene heatmap saved\")\n",
    "    \n",
    "    def run_complete_analysis(self, count_matrix_path, metadata_path, \n",
    "                             group_column, case_label, control_label, \n",
    "                             covariates=None, normalize_microarray=True,\n",
    "                             variance_percentile=None, custom_wgcna_params=None):\n",
    "        \n",
    "        # Load data\n",
    "        self.load_data(count_matrix_path, metadata_path)\n",
    "        \n",
    "        # Preprocess based on data type\n",
    "        if self.data_type == 'rna_seq':\n",
    "            self.preprocess_rnaseq(group_column, case_label, control_label)\n",
    "        elif self.data_type == 'microarray':\n",
    "            self.preprocess_microarray(group_column, case_label, control_label, \n",
    "                                      covariates=covariates, \n",
    "                                      normalize=normalize_microarray)\n",
    "        else:\n",
    "            raise ValueError(\"data_type must be 'rna_seq' or 'microarray'\")\n",
    "        \n",
    "        # Prepare WGCNA input\n",
    "        self.prepare_wgcna_input(custom_variance_percentile=variance_percentile)\n",
    "        \n",
    "        # Select soft power\n",
    "        self.select_soft_power()\n",
    "        \n",
    "        # Construct network\n",
    "        self.construct_network(custom_params=custom_wgcna_params)\n",
    "        \n",
    "        # Analyze DEGs\n",
    "        self.analyze_deg_modules()\n",
    "        \n",
    "        # Create visualizations\n",
    "        self.create_visualizations()\n",
    "        \n",
    "        \n",
    "        \n",
    "        return self\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "b84d04b8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=== LOADING DATA ===\n",
      "  Initial dimensions: (19278, 12)\n",
      "  Aligned samples: 12\n",
      "\n",
      "=== PREPROCESSING RNA-SEQ DATA ===\n",
      "  Method: DESeq2 with variance stabilizing transformation (VST)\n",
      "  After low-count filtering: (19278, 12)\n",
      "  Running DESeq2...\n",
      "Using None as control genes, passed at DeseqDataSet initialization\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Fitting size factors...\n",
      "... done in 0.01 seconds.\n",
      "\n",
      "Fitting dispersions...\n",
      "... done in 4.01 seconds.\n",
      "\n",
      "Fitting dispersion trend curve...\n",
      "... done in 0.49 seconds.\n",
      "\n",
      "Fitting MAP dispersions...\n",
      "... done in 4.33 seconds.\n",
      "\n",
      "Fitting LFCs...\n",
      "... done in 2.94 seconds.\n",
      "\n",
      "Calculating cook's distance...\n",
      "... done in 0.02 seconds.\n",
      "\n",
      "Replacing 0 outlier genes.\n",
      "\n",
      "Fitting size factors...\n",
      "... done in 0.01 seconds.\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fit type used for VST : parametric\n",
      "Using None as control genes, passed at DeseqDataSet initialization\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Fitting dispersions...\n",
      "... done in 4.60 seconds.\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  ✓ VST normalization complete\n",
      "  Normalized data range: [5.61, 20.68]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Running Wald tests...\n",
      "... done in 1.14 seconds.\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Log2 fold change & Wald test p-value: GSM_Label Disease vs Control\n",
      "               baseMean  log2FoldChange     lfcSE      stat    pvalue  \\\n",
      "Gene_symbol                                                             \n",
      "A1BG         149.330525        0.689565  0.474934  1.451916  0.146525   \n",
      "NAT2           0.835028        0.884032  2.552286  0.346369  0.729066   \n",
      "ADA            6.026300       -0.562863  1.728799 -0.325580  0.744742   \n",
      "CDH2         534.411398        0.760583  0.207163  3.671417  0.000241   \n",
      "AKT3         772.284063       -0.328675  0.167813 -1.958580  0.050162   \n",
      "...                 ...             ...       ...       ...       ...   \n",
      "PTBP3        317.668567        0.371334  0.310368  1.196432  0.231528   \n",
      "KCNE2         10.398638       -0.795574  0.746697 -1.065458  0.286669   \n",
      "DGCR2        689.784859       -0.359165  0.279178 -1.286509  0.198266   \n",
      "CASP8AP2     234.654325        0.170190  0.278357  0.611409  0.540929   \n",
      "SCO2         278.175891        0.108776  0.350396  0.310437  0.756229   \n",
      "\n",
      "                 padj  \n",
      "Gene_symbol            \n",
      "A1BG         0.519606  \n",
      "NAT2              NaN  \n",
      "ADA          0.930836  \n",
      "CDH2         0.011332  \n",
      "AKT3         0.311045  \n",
      "...               ...  \n",
      "PTBP3        0.627958  \n",
      "KCNE2        0.679673  \n",
      "DGCR2        0.587841  \n",
      "CASP8AP2     0.843364  \n",
      "SCO2         0.934666  \n",
      "\n",
      "[19278 rows x 6 columns]\n",
      "  DEGs found: 434 (padj<0.05, |log2FC|>1)\n",
      "  Variance filtering: Keep top 75% variable genes\n",
      "  Variance threshold: 0.052\n",
      "  WGCNA input: 12 samples × 14458 genes\n",
      "  Platform: RNA_SEQ\n",
      "  Target R² threshold: 0.8\n",
      "  Power range: (1, 20)\n",
      "  Computing correlation matrix...\n",
      "  Using 5000 random genes for power selection (dataset has 14458)\n",
      "  Testing soft powers...\n",
      "\n",
      "  Selecting optimal power...\n",
      "\n",
      "  ✓ Selected soft power: β = 8\n",
      "    Scale-free R²: 0.851\n",
      "    Mean connectivity: 51.73\n",
      "    Interpretation: Excellent scale-free fit\n",
      "  Platform-optimized parameters (RNA_SEQ):\n",
      "    min_module_size = 30\n",
      "    deep_split = 2 (0=strict, 4=very sensitive)\n",
      "    detect_cut_height = 0.995\n",
      "    merge_cut_height = 0.15\n",
      "\n",
      "  Applying soft power: β = 8\n",
      "  Computing Topological Overlap Matrix (TOM)...\n",
      "  ✓ TOM calculation complete\n",
      "  Performing hierarchical clustering...\n",
      "\n",
      "=== DETECTING MODULES (Dynamic Tree Cut) ===\n",
      "  Min module size: 30\n",
      "  deepSplit: 2\n",
      "  Cut height: 0.9942 (detectCutHeight: 0.995)\n",
      "  PAM stage: True\n",
      "  Initial clusters: 12\n",
      "  Modules after filtering: 6\n",
      "  Unassigned genes: 76\n",
      "  PAM stage: Reassigned 76 genes\n",
      "\n",
      "=== CALCULATING MODULE EIGENGENES ===\n",
      "  Method: First principal component (PCA) of module expression\n",
      "    module_3: 85 genes, variance explained = 47.12%\n",
      "    module_6: 14038 genes, variance explained = 29.83%\n",
      "    module_5: 118 genes, variance explained = 44.33%\n",
      "    module_2: 81 genes, variance explained = 52.50%\n",
      "    module_1: 98 genes, variance explained = 53.65%\n",
      "    module_4: 38 genes, variance explained = 56.53%\n",
      "\n",
      "  Calculated eigengenes for 6 modules\n",
      "\n",
      "=== Merging Close Modules (cutHeight=0.15) ===\n",
      "  Modules before merging: 6\n",
      "  Modules after merging: 6\n",
      "\n",
      "=== FINAL MODULE SUMMARY ===\n",
      "  Total modules: 6\n",
      "  Genes in modules: 14458\n",
      "  Unassigned (grey): 0\n",
      "\n",
      "  Module size distribution:\n",
      "    module_6: 14038 genes\n",
      "    module_5: 118 genes\n",
      "    module_1: 98 genes\n",
      "    module_3: 85 genes\n",
      "    module_2: 81 genes\n",
      "    module_4: 38 genes\n",
      "\n",
      "  Quality metrics:\n",
      "    Average module size: 2409.7 genes\n",
      "    Assignment rate: 100.0%\n",
      "\n",
      "=== ANALYZING DEGS IN MODULES ===\n",
      "  Total DEGs: 434\n",
      "  DEGs in WGCNA network: 434 (100.0%)\n",
      "\n",
      "  DEG distribution across modules:\n",
      "    module_6: 434 DEGs / 14038 genes (enrichment: 1.03x)\n",
      "\n",
      "  Computing co-expression metrics (TOM threshold = 0.1)...\n",
      "  Calculating module membership (kME)...\n",
      "\n",
      " Top 10 hub DEGs (highest co-expression):\n",
      "   Gene   Module  N_CoExpressed_Genes  Module_Membership    Log2FC\n",
      " SLC1A2 module_6                  106          -0.393695  1.568525\n",
      "  SIAH3 module_6                   99           0.139973 -1.038241\n",
      "  RGS16 module_6                   99           0.477098 -1.632268\n",
      "PLEKHB1 module_6                   91          -0.451463  1.515008\n",
      "   BTG3 module_6                   88          -0.023937  3.577588\n",
      "  ACBD7 module_6                   86          -0.613885  1.659547\n",
      "  TRPM3 module_6                   85          -0.291788  2.568120\n",
      " KLHL13 module_6                   83           0.241842 -1.113201\n",
      " FER1L5 module_6                   83          -0.439254  3.414805\n",
      "    ALK module_6                   82           0.134887  3.602451\n",
      "  Creating truncated dendrogram (14458 genes)...\n",
      "  Dendrogram saved\n",
      "  ✓ Eigengene heatmap saved\n",
      "  ✓ All visualizations complete!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 1400x600 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "\n",
    "if __name__ == \"__main__\":\n",
    "    \n",
    "    # Example 1: RNA-seq analysis\n",
    "    wgcna_rnaseq = PyWGCNA(data_type='rna_seq', output_dir='output_rnaseq_wgcna')\n",
    "    wgcna_rnaseq.run_complete_analysis(\n",
    "        count_matrix_path=\"/backup/as36275d/abhishek/Kamini/backup/GSE169755_counts_sym.csv\",\n",
    "        metadata_path=\"/backup/as36275d/abhishek/Kamini/backup/METADATA_GSE169755.csv\",\n",
    "        group_column=\"GSM_Label\",\n",
    "        case_label=\"Disease\",\n",
    "        control_label=\"Control\"\n",
    "    )\n",
    "    \n",
    "   \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "34f787df",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "================================================================================\n",
      "=== SCIENTIFICALLY OPTIMIZED PyWGCNA PIPELINE (MICROARRAY) ===\n",
      "================================================================================\n",
      "\n",
      "=== LOADING DATA ===\n",
      "  Initial dimensions: (14205, 64)\n",
      "  Aligned samples: 64\n",
      "\n",
      "=== PREPROCESSING MICROARRAY DATA ===\n",
      "  Method: limma with empirical Bayes moderation\n",
      "  Data appears log-scale (max=15.56)\n",
      "  Applying quantile normalization...\n",
      "  ✓ Normalization complete\n",
      "  Normalized data range: [-5.20, 5.20]\n",
      "  Creating design matrix...\n",
      "  Fitting linear model...\n",
      "  Applying empirical Bayes moderation...\n",
      "  Extracting differential expression results...\n",
      "  DEGs found: 9 (FDR<0.05, |log2FC|>1)\n",
      "\n",
      "=== PREPARING WGCNA INPUT ===\n",
      "  Variance filtering: Keep top 50% variable genes\n",
      "  Variance threshold: 0.022\n",
      "  WGCNA input: 64 samples × 7102 genes\n",
      "\n",
      "=== SELECTING SOFT-THRESHOLDING POWER ===\n",
      "  Platform: MICROARRAY\n",
      "  Target R² threshold: 0.8\n",
      "  Power range: (1, 20)\n",
      "  Computing correlation matrix...\n",
      "  Using 5000 random genes for power selection (dataset has 7102)\n",
      "  Testing soft powers...\n",
      "\n",
      "  Selecting optimal power...\n",
      "\n",
      "  ✓ Selected soft power: β = 7\n",
      "    Scale-free R²: 0.805\n",
      "    Mean connectivity: 37.16\n",
      "    Interpretation: Good scale-free fit\n",
      "\n",
      "=== CONSTRUCTING CO-EXPRESSION NETWORK ===\n",
      "  Platform-optimized parameters (MICROARRAY):\n",
      "    min_module_size = 30\n",
      "    deep_split = 3 (0=strict, 4=very sensitive)\n",
      "    detect_cut_height = 0.99\n",
      "    merge_cut_height = 0.25\n",
      "\n",
      "  Applying soft power: β = 7\n",
      "  Computing Topological Overlap Matrix (TOM)...\n",
      "  ✓ TOM calculation complete\n",
      "  Performing hierarchical clustering...\n",
      "\n",
      "=== DETECTING MODULES (Dynamic Tree Cut) ===\n",
      "\n",
      "=== Dynamic Tree Cut Parameters ===\n",
      "  Min module size: 30\n",
      "  deepSplit: 3\n",
      "  Cut height: 0.9974 (detectCutHeight: 0.99)\n",
      "  PAM stage: True\n",
      "  Initial clusters: 118\n",
      "  Modules after filtering: 6\n",
      "  Unassigned genes: 404\n",
      "  PAM stage: Reassigned 404 genes\n",
      "\n",
      "=== CALCULATING MODULE EIGENGENES ===\n",
      "  Method: First principal component (PCA) of module expression\n",
      "    module_6: 6670 genes, variance explained = 37.42%\n",
      "    module_5: 55 genes, variance explained = 44.38%\n",
      "    module_4: 156 genes, variance explained = 44.35%\n",
      "    module_3: 81 genes, variance explained = 32.63%\n",
      "    module_2: 67 genes, variance explained = 34.14%\n",
      "    module_1: 73 genes, variance explained = 36.76%\n",
      "\n",
      "  ✓ Calculated eigengenes for 6 modules\n",
      "\n",
      "=== Merging Close Modules (cutHeight=0.25) ===\n",
      "  Modules before merging: 6\n",
      "  Modules after merging: 6\n",
      "\n",
      "=== FINAL MODULE SUMMARY ===\n",
      "  Total modules: 6\n",
      "  Genes in modules: 7102\n",
      "  Unassigned (grey): 0\n",
      "\n",
      "  Module size distribution:\n",
      "    module_6: 6670 genes\n",
      "    module_4: 156 genes\n",
      "    module_3: 81 genes\n",
      "    module_1: 73 genes\n",
      "    module_2: 67 genes\n",
      "    module_5: 55 genes\n",
      "\n",
      "  Quality metrics:\n",
      "    Average module size: 1183.7 genes\n",
      "    Assignment rate: 100.0%\n",
      "\n",
      "=== ANALYZING DEGS IN MODULES ===\n",
      "  Total DEGs: 9\n",
      "  DEGs in WGCNA network: 9 (100.0%)\n",
      "\n",
      "  DEG distribution across modules:\n",
      "    module_6: 9 DEGs / 6670 genes (enrichment: 1.06x)\n",
      "\n",
      "  Computing co-expression metrics (TOM threshold = 0.1)...\n",
      "  Calculating module membership (kME)...\n",
      "\n",
      "  ✓ Top 10 hub DEGs (highest co-expression):\n",
      "   Gene   Module  N_CoExpressed_Genes  Module_Membership    Log2FC\n",
      "   HBA1 module_6                    2           0.303963 -1.429038\n",
      "   HBA2 module_6                    2           0.303963 -1.429038\n",
      "    HBB module_6                    2           0.345020 -1.110339\n",
      " HOMER3 module_6                    0           0.394455  1.043112\n",
      "ALDH1A1 module_6                    0          -0.200644 -1.181969\n",
      "   FHL2 module_6                    0          -0.447011 -1.042283\n",
      "    CLC module_6                    0           0.292960 -1.171635\n",
      "  IGF1R module_6                    0           0.035709 -1.071224\n",
      "   PBX1 module_6                    0          -0.617046 -1.239126\n",
      "\n",
      "=== CREATING VISUALIZATIONS ===\n",
      "  Creating truncated dendrogram (7102 genes)...\n",
      "  ✓ Dendrogram saved\n",
      "  ✓ Eigengene heatmap saved\n",
      "  ✓ All visualizations complete!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 1400x600 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "## Microarray Data ##  # Example 2: Microarray analysis\n",
    "if __name__ == \"__main__\":\n",
    "    wgcna_microarray = PyWGCNA(data_type='microarray', output_dir='output_microarray_wgcna')\n",
    "    wgcna_microarray.run_complete_analysis(\n",
    "        count_matrix_path=\"/backup/as36275d/abhishek/Kamini/test/Data_extraction/AML/GSE9476/GSE9476_expression.csv\",\n",
    "        metadata_path=\"/backup/as36275d/abhishek/Kamini/test/Data_extraction/AML/GSE9476/GSE9476_metadata.csv\",\n",
    "        group_column=\"Gsm_label\",\n",
    "        case_label=\"Disease\",\n",
    "        control_label=\"Control\",\n",
    "        covariates=None,  # Add covariates if needed: ['age', 'sex']\n",
    "        normalize_microarray=True  # Set to True if quantile normalization needed\n",
    "    )\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "az2",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
